\section*{Chapter 6. Markov, Poisson and Jump processes}
\subsection*{6.1: Markov chains and processes}
\begin{definition*} 
A discrete time stochastic process $\{X_n, n = 0, 1, \dots\}$ with each RV
$X_n$ taking values in a measurable space $(\mathbb{S},\B)$ is called a Markov
chain if for every non-negative integer $n$ and any set $A \in \B$, almost
surely $\Pb(X_{n+1} \in A | X_0, \dots, X_n) = \Pb(X_{n+1} \in A | X_n)$. The
set $\mathbb{S}$ is called the state space of the Markov chain.
\end{definition*} 

\begin{remark*} 
This above definition is equivalent to the identity $\E(f(X_{n+1}) | X_1, \dots,
X_n) = \E(f(X_{n+1}) | X_n)$ holding almost surely for each bounded measurable
function $f(\cdot)$.
\end{remark*} 

\begin{definition*} 
A homogeneous Markov chain is a Markov chain that has a modification for which
$\Pb(X_{n+1} \in A | X_n)$ does not depend on $n$ (except via the value of
$X_n$).
\end{definition*} 

\begin{definition*} 
To each homogeneous Markov chain $\{X_n\}$ with values in a closed subset
$\mathbb{S}$ of $\R$ correspond its stationary transition probabilities $p(A|x)$
such that $p(\cdot | x)$ is a probability measure on $(\mathbb{S}, \B)$ for any
$x \in \mathbb{S}$; $p(A|\cdot)$ is measurable on $\B$ for any $A \in \B$, and
almost surely $p(A | X_n) = \Pb(X_{n+1} \in A | X_n)$ for all $n \ge 0$.
\end{definition*} 

\begin{remark*} 
Many Markov chains are not martingales. For example, a sequence of independent
variables $X_n$ is a Markov chain, but unless $\Pb(X_n = c) = 1$ for some
non-random $c$ and all $n$, it is not a martingale. Similarly, many martingales
do no have the Markov property. For example, the sequence $X_n = X_0(1 + S_n)$
with $X_0$ uniformly chosen in $\{1, 3\}$ independently of the simple random
walk $S_n$ of zero mean, is a martingale of zero-mean is a martingale, but not a
Markov chain.
\end{remark*} 

\begin{remark*} (Notation)
Let $\Pb_x$ denote the law of the homogeneous Markov chain starting at $X_0 =
x$.
\end{remark*} 

\begin{definition*} 
The initial distribution of a Markov chain is the probability measure $\pi(A) =
P(X_0 \in A)$ on $(\mathbb{S}, \B)$.
\end{definition*} 

\begin{proposition*} (Strong Markov Property)
Let $X_n$ be a homogeneous Markov chain. Then,
$\Pb((X_\tau, X_{\tau + 1}, \dots, X_{\tau + k}) \in B | \G_\tau)
= \Pb_{X_\tau} ((X_0, \dots, X_k) \in B)$ holds for any almost surely finite
stopping time $\tau$ with respect to its canonical filtration $\G_n$, with
$\G_\tau$ denoting the corresponding stopped $\sigma$-field.
\end{proposition*} 

\begin{definition*} 
A stochastic process $X(t)$ indexed by $t \in [0, \infty)$ and taking values in
a measurable space $(\mathbb{S}, \B)$ is called a Markov process if for any $t,
u \ge 0$ and $A \in \B$ we have that almost surely
$\Pb(X(t + u) \in A | \sigma(X(s), s \le t)) = \Pb(X(t + u) \in A | X(t))$.
Equivalently, we call $X(t)$ a Markov process if for any $t, u \ge 0$ and any
bounded measurable function $f(\cdot)$ on $(\mathbb{S}, \B)$, almost surely,
$\E(f(X(t + u)) | \sigma(X(s), s \le t)) = \E(f(X(t + u)) | X(t))$. The set
$\mathbb{S}$ is called the state space of the Markov process.
\end{definition*} 

\begin{definition*} 
For each $t > s$ and fixed $s \in \mathbb{S}$ there exists a probability measure
$p_{t, s} (\cdot | x)$ on $(\mathbb{S}, \B)$ such that for each fixed $A \in
\B$, the function $p_{t, s}(A | \cdot)$ is measurable and
$\Pb(X(t) \in A | X(s)) = \E(I_{X(t) \in A} | X(s)) = p_{t, s}(A | X(s))$ almost
surely. Such a collection $p_{t, s}(A | x)$ is called the transition
probabilities for the Markov process $\{X(t)\}$.
\end{definition*} 

\begin{definition*} 
We say that $p_{t, s}(A|x)$ for $t > s \ge 0$, $x \in \mathbb{S}$ and $A \in \B$
are regular transition probabilities if $p_{t, s}(\cdot | x)$ are probability
measures on $(\mathbb{S}, \B)$, the functions $p_{t, s} (A | \cdot)$ are Borel
measurable and Chapman-Kolmogorov equations $p_{t, s} (A | x) = \int p_{t, u} (A
| y) p_{u, s} (dy | x)$, hold for every $t > u > s \ge 0$, $x \in \mathbb{S}$
and $A \in \B$.
\end{definition*} 

\begin{theorem*} 
Given regular transition probabilities $p_{t, s}(\cdot | \cdot)$ and a
probability measure $\pi(\cdot)$ on $(\mathbb{S}, \B)$, the identities
$\Pb(X(t_k) \in A_k, \dots, X(t_0) \in A_0) = \int_{A_0} \cdots \int_{A_k}
p_{t_k, t_{k-1}} (dx_k | x_{k-1}) \cdot p_{t_1, t_0} (dx_1 | x_0) \pi (dx_0)$
define the finite dimensional distributions of a Markov process $\{X(t)\}$
having the specified transition probabilities and the initial distribution
$\pi$.
\end{theorem*} 

\begin{definition*} 
A homogeneous Markov process is a Markov process with regular transition
probabilities of the form $p_{t, s} (\cdot | \cdot) = p_{t-s} (\cdot | \cdot)$,
which in turn are called the stationary regular transition probabilities.
\end{definition*} 

\begin{proposition*} 
Suppose $X(t)$ is a homogeneous Markov process, with $\G_t$ denoting its
canonical filtration $\sigma(X(s), s \le t$ and $\Pb_x$ the law of the process
starting at $X(0) = x$. Then, any such process has the regular Markov property.
That is, $\Pb_x(X(\cdot + \tau) \in \Gamma | \G_\tau) = \Pb_{X(\tau)} (X(\cdot)
\in \Gamma)$ almost surely for any $x \in \R$, non-random $\tau \ge 0$ and
$\Gamma$ in the cylindrical $\sigma$-field $\B^{[0, \infty)}$.
\end{proposition*} 

\begin{exercise*} 
Let $\{X_t, t \ge 0\}$ be a Markov process of state state $\mathbb{S}$. Suppose
$h_t: \mathbb{S} \rightarrow \mathbb{S}'$ are measurable and invertible for any
fixed $t \ge 0$ and $g: [0, \infty) \rightarrow [0, \infty)$ is invertible and
strictly increasing.
\begin{itemize}
\item Verify that $Y_t = h_t(X_{g(t)})$ is a Markov process.
\item Show that if $\{X_t\}$ is a homogeneous Markov process then so if
$\{h(X_t)\}$.
\end{itemize}
\end{exercise*} 

\begin{proposition*} 
Every continuous time stochastic process of independent increments is a Markov
process. Further, every continuous time SP of stationary independent increments
is a homogeneous Markov process.
\end{proposition*} 

\begin{remark*} 
To re-cap, we have seen three main ways of showing that a SP $\{X_t, t \ge
0\}$ is a Markov process:
\begin{itemize}
\item Computing $\Pb(X_{t+h} \in A | \G_t)$ directly and checking that is only
depends on $X_t$ (and not on $X_s$ for $s < t$).

\item Showing that the process has independent increments and applying
the above proposition.

\item Showing that it is an invertible function of another Markov process, and
appealing to the above Exercise.
\end{itemize}
\end{remark*} 

\begin{proposition*} 
If a Markov process or a Markov chain is also a stationary process, then it is a
homogeneous Markov process, or Markov chain, respectively.
\end{proposition*} 

\begin{remark*} 
Note however that many homogeneous Markov processes and Markov chains are not
stationary processes. Convince yourself that among such examples are the
Brownian motion (in continuous time) and the random walk (in discrete time).
\end{remark*} 

\begin{definition*} 
A homogeneous Markov process is called a strong Markov process if
$\Pb_x(X(\cdot + \tau) \in \Gamma | \G_\tau) = \Pb_{X(\tau)} (X(\cdot)
\in \Gamma)$ holds for any almost surely finite stopping time $\tau$ with
respect to its canonical filtration $\G_\tau$.
\end{definition*} 

\begin{corollary*} 
The Brownian motion is a strong Markov process.
\end{corollary*} 

\begin{proposition*} 
The Markov property (same equation as the definition above) holds for any
stopping time $\tau$ (with respect to the canonical filtration of the
homogeneous Markov process $\{X(t)\}$), provided $\tau$ assumes at most a
countable number of non-random values.
\end{proposition*} 







\subsection*{6.2: Poisson process, Exponential inter-arrivals and order statistics}
\subsection*{6.3: Markov jump processes, compound Poisson processes}