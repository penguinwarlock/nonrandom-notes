\section*{Chapter 6. Markov, Poisson and Jump processes}
\subsection*{6.1: Markov chains and processes}
\begin{definition*} 
A discrete time stochastic process $\{X_n, n = 0, 1, \dots\}$ with each RV
$X_n$ taking values in a measurable space $(\mathbb{S},\B)$ is called a Markov
chain if for every non-negative integer $n$ and any set $A \in \B$, almost
surely $\Pb(X_{n+1} \in A | X_0, \dots, X_n) = \Pb(X_{n+1} \in A | X_n)$. The
set $\mathbb{S}$ is called the state space of the Markov chain.
\end{definition*} 

\begin{remark*} 
This above definition is equivalent to the identity $\E(f(X_{n+1}) | X_1, \dots,
X_n) = \E(f(X_{n+1}) | X_n)$ holding almost surely for each bounded measurable
function $f(\cdot)$.
\end{remark*} 

\begin{definition*} 
A homogeneous Markov chain is a Markov chain that has a modification for which
$\Pb(X_{n+1} \in A | X_n)$ does not depend on $n$ (except via the value of
$X_n$).
\end{definition*} 

\begin{definition*} 
To each homogeneous Markov chain $\{X_n\}$ with values in a closed subset
$\mathbb{S}$ of $\R$ correspond its stationary transition probabilities $p(A|x)$
such that $p(\cdot | x)$ is a probability measure on $(\mathbb{S}, \B)$ for any
$x \in \mathbb{S}$; $p(A|\cdot)$ is measurable on $\B$ for any $A \in \B$, and
almost surely $p(A | X_n) = \Pb(X_{n+1} \in A | X_n)$ for all $n \ge 0$.
\end{definition*} 

\begin{remark*} 
Many Markov chains are not martingales. For example, a sequence of independent
variables $X_n$ is a Markov chain, but unless $\Pb(X_n = c) = 1$ for some
non-random $c$ and all $n$, it is not a martingale. Similarly, many martingales
do no have the Markov property. For example, the sequence $X_n = X_0(1 + S_n)$
with $X_0$ uniformly chosen in $\{1, 3\}$ independently of the simple random
walk $S_n$ of zero mean, is a martingale of zero-mean is a martingale, but not a
Markov chain.
\end{remark*} 

\begin{remark*} (Notation)
Let $\Pb_x$ denote the law of the homogeneous Markov chain starting at $X_0 =
x$.
\end{remark*} 

\begin{definition*} 
The initial distribution of a Markov chain is the probability measure $\pi(A) =
P(X_0 \in A)$ on $(\mathbb{S}, \B)$.
\end{definition*} 

\begin{proposition*} (Strong Markov Property)
Let $X_n$ be a homogeneous Markov chain. Then,
$\Pb((X_\tau, X_{\tau + 1}, \dots, X_{\tau + k}) \in B | \G_\tau)
= \Pb_{X_\tau} ((X_0, \dots, X_k) \in B)$ holds for any almost surely finite
stopping time $\tau$ with respect to its canonical filtration $\G_n$, with
$\G_\tau$ denoting the corresponding stopped $\sigma$-field.
\end{proposition*} 

\begin{definition*} 
A stochastic process $X(t)$ indexed by $t \in [0, \infty)$ and taking values in
a measurable space $(\mathbb{S}, \B)$ is called a Markov process if for any $t,
u \ge 0$ and $A \in \B$ we have that almost surely
$\Pb(X(t + u) \in A | \sigma(X(s), s \le t)) = \Pb(X(t + u) \in A | X(t))$.
Equivalently, we call $X(t)$ a Markov process if for any $t, u \ge 0$ and any
bounded measurable function $f(\cdot)$ on $(\mathbb{S}, \B)$, almost surely,
$\E(f(X(t + u)) | \sigma(X(s), s \le t)) = \E(f(X(t + u)) | X(t))$. The set
$\mathbb{S}$ is called the state space of the Markov process.
\end{definition*} 

\begin{definition*} 
For each $t > s$ and fixed $s \in \mathbb{S}$ there exists a probability measure
$p_{t, s} (\cdot | x)$ on $(\mathbb{S}, \B)$ such that for each fixed $A \in
\B$, the function $p_{t, s}(A | \cdot)$ is measurable and
$\Pb(X(t) \in A | X(s)) = \E(I_{X(t) \in A} | X(s)) = p_{t, s}(A | X(s))$ almost
surely. Such a collection $p_{t, s}(A | x)$ is called the transition
probabilities for the Markov process $\{X(t)\}$.
\end{definition*} 

\begin{definition*} 
We say that $p_{t, s}(A|x)$ for $t > s \ge 0$, $x \in \mathbb{S}$ and $A \in \B$
are regular transition probabilities if $p_{t, s}(\cdot | x)$ are probability
measures on $(\mathbb{S}, \B)$, the functions $p_{t, s} (A | \cdot)$ are Borel
measurable and Chapman-Kolmogorov equations $p_{t, s} (A | x) = \int p_{t, u} (A
| y) p_{u, s} (dy | x)$, hold for every $t > u > s \ge 0$, $x \in \mathbb{S}$
and $A \in \B$.
\end{definition*} 

\begin{theorem*} 
Given regular transition probabilities $p_{t, s}(\cdot | \cdot)$ and a
probability measure $\pi(\cdot)$ on $(\mathbb{S}, \B)$, the identities
$\Pb(X(t_k) \in A_k, \dots, X(t_0) \in A_0) = \int_{A_0} \cdots \int_{A_k}
p_{t_k, t_{k-1}} (dx_k | x_{k-1}) \cdot p_{t_1, t_0} (dx_1 | x_0) \pi (dx_0)$
define the finite dimensional distributions of a Markov process $\{X(t)\}$
having the specified transition probabilities and the initial distribution
$\pi$.
\end{theorem*} 

\begin{definition*} 
A homogeneous Markov process is a Markov process with regular transition
probabilities of the form $p_{t, s} (\cdot | \cdot) = p_{t-s} (\cdot | \cdot)$,
which in turn are called the stationary regular transition probabilities.
\end{definition*} 

\begin{proposition*} 
Suppose $X(t)$ is a homogeneous Markov process, with $\G_t$ denoting its
canonical filtration $\sigma(X(s), s \le t$ and $\Pb_x$ the law of the process
starting at $X(0) = x$. Then, any such process has the regular Markov property.
That is, $\Pb_x(X(\cdot + \tau) \in \Gamma | \G_\tau) = \Pb_{X(\tau)} (X(\cdot)
\in \Gamma)$ almost surely for any $x \in \R$, non-random $\tau \ge 0$ and
$\Gamma$ in the cylindrical $\sigma$-field $\B^{[0, \infty)}$.
\end{proposition*} 

\begin{exercise*} 
Let $\{X_t, t \ge 0\}$ be a Markov process of state state $\mathbb{S}$. Suppose
$h_t: \mathbb{S} \rightarrow \mathbb{S}'$ are measurable and invertible for any
fixed $t \ge 0$ and $g: [0, \infty) \rightarrow [0, \infty)$ is invertible and
strictly increasing.
\begin{itemize}
\item Verify that $Y_t = h_t(X_{g(t)})$ is a Markov process.
\item Show that if $\{X_t\}$ is a homogeneous Markov process then so if
$\{h(X_t)\}$.
\end{itemize}
\end{exercise*} 

\begin{proposition*} 
Every continuous time stochastic process of independent increments is a Markov
process. Further, every continuous time SP of stationary independent increments
is a homogeneous Markov process.
\end{proposition*} 

\begin{remark*} 
To re-cap, we have seen three main ways of showing that a SP $\{X_t, t \ge
0\}$ is a Markov process:
\begin{itemize}
\item Computing $\Pb(X_{t+h} \in A | \G_t)$ directly and checking that is only
depends on $X_t$ (and not on $X_s$ for $s < t$).

\item Showing that the process has independent increments and applying
the above proposition.

\item Showing that it is an invertible function of another Markov process, and
appealing to the above Exercise.
\end{itemize}
\end{remark*} 

\begin{proposition*} 
If a Markov process or a Markov chain is also a stationary process, then it is a
homogeneous Markov process, or Markov chain, respectively.
\end{proposition*} 

\begin{remark*} 
Note however that many homogeneous Markov processes and Markov chains are not
stationary processes. Convince yourself that among such examples are the
Brownian motion (in continuous time) and the random walk (in discrete time).
\end{remark*} 

\begin{definition*} 
A homogeneous Markov process is called a strong Markov process if
$\Pb_x(X(\cdot + \tau) \in \Gamma | \G_\tau) = \Pb_{X(\tau)} (X(\cdot)
\in \Gamma)$ holds for any almost surely finite stopping time $\tau$ with
respect to its canonical filtration $\G_\tau$.
\end{definition*} 

\begin{corollary*} 
The Brownian motion is a strong Markov process.
\end{corollary*} 

\begin{proposition*} 
The Markov property (same equation as the definition above) holds for any
stopping time $\tau$ (with respect to the canonical filtration of the
homogeneous Markov process $\{X(t)\}$), provided $\tau$ assumes at most a
countable number of non-random values.
\end{proposition*} 







\subsection*{6.2: Poisson process, Exponential inter-arrivals and order statistics}

\begin{condition*}
$\boxed{C_0}$. Each sample path $N_t(\omega)$ is piecewise constant, nondecreasing, right continuous, with $N_0(\omega)=0$ , all jump discontinuities are of size one, and there are infinitely many of them.
\end{condition*}

Associated with each sample path $N_t(\omega)$ satisfying $\boxed{C_0}$ are the jump times $0=T_0<T_1<\dots$ with $T_k = \inf\{t \geq 0:N_t\geq k\}$ for each $k$, or equivalently $N_t = \sup\{k \geq 0 : T_k \leq t\}$. 

Recall that $N$ has the $\text{Poisson}(\mu)$ law if $P(N=k)=\frac{\mu^k}{k!}e^{-\mu}$.

\begin{condition*}
$\boxed{C_1}$. For any $k$ and any $0<t_1<\dots<t_k$, the increments $N_{t_1}, N_{t_2}-N_{t_1},\dots,N_{t_k}-N_{t_{k-1}}$ are independent random variables and fro some $\lambda > 0$ and all $t>s\geq0$ the increment $N_t-N_s$ has the $\text{Poisson}(\lambda(t-s))$ law.
\end{condition*}

\begin{definition*}
Among the processes satisfying $\boxed{C_0}$ the Poisson process is the unique one satisfying $\boxed{C_1}$.
\end{definition*}

\begin{corollary*}
$M_t = N_t - \lambda t$ is a MG. Also, it is square-integrable and $M_t^2 - \lambda t$ is a martingale for the (right-continuous) filtration $\sigma(N_s,s\leq t)$.
\end{corollary*}

\begin{proposition*}
The Poisson processes are the only stochastic processes with stationary independent increments. Also, the Poisson process is a homogeneous Markov process; it has stationary regular transition probabilities $p_t(x+k|x)=\frac{(\lambda t)^k}{k!} e^{-\lambda t}, k,x\geq 0$. Also the Poisson process is a strong Markov process.
\end{proposition*}

\begin{proposition*}[Memoryless property of the Exponential law]
We say that a r.v. $T$ has $\text{Exponential}(\lambda)$ law if $\Pb(T>t)=e^{-\lambda t}$. Except for $T=0$ w.p.1 these are the only laws for which $\Pb(T>x+y|T>y)=\Pb(T>x)$ for all $x,y\geq0$.
\end{proposition*}

\begin{condition*}
$\boxed{C_2}$. The gaps between jump times $T_k-T_{k-1}$ are i.i.d. r.v.s each of $\text{Exponential}(\lambda)$ law.
\end{condition*}

\begin{proposition*}
A stochastic process $N_t$ that satisfies $\boxed{C_0}$ is a Poisson process of rate $\lambda$ iff it satisfies $\boxed{C_2}$.
\end{proposition*}

\begin{remark*}
Obviously the sample path of the Poisson process are never continuous. However, $\Pb(N_{t+h} - N_t \geq 1) = 1-e^{-\lambda h} \to 0$ as $h \downarrow 0$, so $\Pb(T_k=t)=0$ so there are no fixed discontinuities (i.e. occuring at non-random times).
\end{remark*}

\begin{proposition*}
Fixing positive $t$ and a positive integer $n$ let $U_i$ be i.i.d. random variables, each uniform on $[0,t]$ and consider their order statisticsc $U_i^*$. That is, permute the order of $U_i$ so that $U_1^*\leq\dots\leq U_n^*$. The joint distribution of $(U_1^*,\dots,U_n^*)$ is precisely that of the first $n$ arrival times $(T_1,\dots,T_n)$ of a Poisson process, conditional on the event $N_t=n$.
\end{proposition*}

